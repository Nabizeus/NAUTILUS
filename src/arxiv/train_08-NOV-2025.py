import os
import time
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from tqdm import tqdm
from src.model import OceanPredictor
from src.data import WindowedOceanDataset
from src.utils import save_checkpoint, load_config, set_seed
import time
import csv
import imageio
from pathlib import Path
import numpy as  np

def log_training_time(region_name, elapsed_minutes, best_val_loss, epochs, batch_size, csv_path= f"logs/training_times_{time.strftime('%Y%m%d_%H%M')}.csv"):
    file_exists = os.path.isfile(csv_path)

    with open(csv_path, mode="a", newline="") as f:
        writer = csv.writer(f)
        # If file is new, write the header
        if not file_exists:
            writer.writerow(["region", "elapsed_minutes", "best_val_loss", "epochs", "batch_size", "time_stamp"])
        # Write values
        #writer.writerow([region_name, round(elapsed_minutes, 2), round(best_val_loss, 4)])
        writer.writerow([
            region_name,
            round(elapsed_minutes, 2),
            round(best_val_loss, 4),
            epochs,
            batch_size,
            time.strftime('%Y-%m-%d %H:%M')
        ])

def train_one_epoch(model, loader, optimizer, loss_fn, device):
    model.train()
    total_loss = 0.0
    for inputs, targets, _ in loader:  # dataset may still yield a dummy mask
        inputs, targets = inputs.to(device), targets.to(device)
        optimizer.zero_grad()
        preds = model(inputs)
        loss = loss_fn(preds, targets)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    return total_loss / len(loader)


def validate(model, loader, loss_fn, device):
    model.eval()
    total_loss = 0.0
    with torch.no_grad():
        for inputs, targets, _ in loader:
            inputs, targets = inputs.to(device), targets.to(device)
            preds = model(inputs)
            loss = loss_fn(preds, targets)
            total_loss += loss.item()
    return total_loss / len(loader)





def main():
    import hydra
    from omegaconf import OmegaConf

    @hydra.main(config_path="../config", config_name="default", version_base=None)
    def run(cfg):
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        os.makedirs(cfg.training.checkpoint_dir, exist_ok=True)

        for region_cfg in cfg.data.regions:
            region_name = region_cfg["name"]
            print(f"\nðŸŒŠ Starting training for region: {region_name}")
            start_time = time.time() # <-- Start timer
            train_ds = WindowedOceanDataset(cfg, split="train", region_name=region_name)
            val_ds = WindowedOceanDataset(cfg, split="val", region_name=region_name)

            def debug_visualize_sample(inputs, region_name, number, out_dir="artifacts/debug_inputs"):
                os.makedirs(out_dir, exist_ok=True)
                # inputs shape: (B, T, C, H, W)
                B, T, C, H, W = inputs.shape
                sample = inputs[0].detach().cpu().numpy()

                fig, axes = plt.subplots(C, T, figsize=(T * 2.5, C * 2.5))
                vars = ["Tracer", "U", "V", "W"]

                for c in range(C):
                    for t in range(T):
                        ax = axes[c, t]
                        im = ax.imshow(sample[t, c, :, :], cmap="viridis")
                        ax.set_title(f"{vars[c]} t={t}")
                        ax.axis("off")
                str_number = str(int(number))
                plt.tight_layout()
                return fig # âœ… Return instead of closing it here

                #save_path = os.path.join(out_dir, f"sample_{region_name}_{str_number}.png")
                #plt.savefig(save_path, dpi=200)
                #plt.close()
                #print(f"ðŸ“¸ Saved debug input grid â†’ {save_path}")

   
            # In train.py, before initializing model:
            x1, x2 = region_cfg["x_range"]
            y1, y2 = region_cfg["y_range"]

            H = y2 - y1  # height is Î”y
            W = x2 - x1  # width is Î”x

 
            # Initialize model for this region
            model = OceanPredictor(cfg, H=H, W=W).to(device)
            optimizer = torch.optim.Adam(model.parameters(), lr=cfg.training.lr)
            scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())

            best_val_loss = float("inf")

        
            train_losses = []
            val_losses = []
        




            z_idx = getattr(train_ds, "z_index", 0)
            print(f"@train.py - line 60 - z_idx = getattr(train_ds): {z_idx}")

            # For collecting frames per epoch
            debug_frames = []



            for epoch in range(cfg.training.epochs):
                model.train()
                train_loss = 0.0
                pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{cfg.training.epochs} [Train]")
                debug_count = 0
                for inputs, targets, mask in pbar:
                    if debug_count % 10 == 0:
                        #print(f"ï¿½~_~T~M [Debug] Sample batch shape: {inputs.shape}")
                        #debug_visualize_sample(inputs, region_name, debug_count)
                        fig = debug_visualize_sample(inputs, region_name, debug_count)  # your existing plotting function
                        fig.canvas.draw()

                        # Convert figure to numpy frame
                        frame = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)
                        frame = frame.reshape(fig.canvas.get_width_height()[::-1] + (3,))

                        debug_frames.append(frame)
                        plt.close(fig)
                    debug_count += 1
                    for inputs, targets, mask in train_loader:
                    
                    
                        # --- Depth-averaged 2D slicing ---
                        if inputs.ndim == 6:
                            inputs = inputs[..., z_idx, :, :] #at z_idx middle of depth range
                            print(f"ðŸª£ Train depth-middle layer input: {inputs.shape}")
                            mean_inputs = np.mean(inputs)
                            mean_targets = np.mean(targets)
                            sigma_inputs = np.stdev(inputs)
                            sigma_targets = np.stdev(targets)
                            print(f"Mean inputs {mean_inputs}")
                            print(f"Mean targets {mean_targets}")
                            print(f"Sigma inputs {stdev_inputs}")
                            print(f"Sigma targets {stdev_targets}")
                            inputs, targets, mask = inputs.to(device), targets.to(device), mask.to(device)

                    preds = model(inputs)
          
                    # Ensure NaN-safe tensors
                    inputs = torch.nan_to_num(inputs)
                    targets = torch.nan_to_num(targets)

                    optimizer.zero_grad(set_to_none=True)
                    with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):
                        # --- NaN/Inf safety in input batch ---
                        if torch.isnan(inputs).any() or torch.isinf(inputs).any():
                            print("âš ï¸ [Train Loop] NaN/Inf detected in inputs! Fixing batch.")
                            inputs = torch.nan_to_num(inputs, nan=0.0, posinf=1e20, neginf=-1e20)

                        preds = model(inputs)

                        # --- NaN/Inf safety in output ---
                        if torch.isnan(preds).any() or torch.isinf(preds).any():
                            print("âš ï¸ [Train Loop] NaN/Inf detected in predictions! Fixing.")
                            preds = torch.nan_to_num(preds, nan=0.0, posinf=1e20, neginf=-1e20)
                
                        loss = masked_mse_loss(preds, targets, mask)

                    if torch.isnan(loss):
                        print("âš ï¸ NaN detected in loss â€” skipping batch")
                        continue

                    scaler.scale(loss).backward()
                    scaler.step(optimizer)
                    scaler.update()

                    train_loss += loss.item()
                    pbar.set_postfix({"train_loss": f"{loss.item():.6f}"})

                train_loss /= max(1, len(train_loader))

                # ==============================
                # ðŸ§ª Validation
                # ==============================
                model.eval()
                val_loss = 0.0
                with torch.no_grad():
                    for inputs, targets, mask in val_loader:
                        inputs, targets, mask =  inputs.to(device), targets.to(device), mask.to(device)
                        if inputs.ndim == 6:
                            inputs_2d = inputs[..., z_idx, :, :] #10 .mean(dim=3)
                        else:
                            inputs_2d = inputs
                        preds = model(inputs_2d)
                        loss = masked_mse_loss(preds, targets, mask)
                        val_loss += loss.item()

                val_loss /= max(1, len(val_loader))
                print(f"âœ… Epoch {epoch+1}: train_loss={train_loss:.6f}, val_loss={val_loss:.6f}")

                train_losses.append(train_loss)
                val_losses.append(val_loss)




                if debug_frames:
                    gif_path = f"artifacts/debug_inputs/{region_name}_epoch_{epoch+1}.gif"
                    imageio.mimsave(gif_path, debug_frames, fps=3)
                    print(f"ðŸŽžï¸ Saved debug GIF for {region_name}, epoch {epoch+1} âžœ {gif_path}")


                # Save checkpoint per region
                if val_loss < best_val_loss:
                    best_val_loss = val_loss
                    save_path = f"checkpoints/{region_name}_best_model.pt"
                    torch.save({
                    "model_state": model.state_dict(),
                    "H": H,
                    "W": W,
                    "epoch": epoch,
                    "optimizer_state": optimizer.state_dict()
                        }, save_path)
                    #print(f"ðŸ’¾ @train.py - line 260 - Saved checkpoint model:  {save_path}")
                    print(f"âœ… Saved best model for {region_name} â†’ {save_path}")
                
            print(f"ðŸ§­ [{region_name}] Epoch {epoch+1}/{cfg.training.epochs} | " f"Train: {train_loss:.4f} | Val: {val_loss:.4f}")



            plt.figure(figsize=(8, 5))
            plt.plot(train_losses, label='Train Loss')
            plt.plot(val_losses, label='Validation Loss')
            #if len(test_losses) > 0:
                #plt.plot(test_losses, label='Test Loss')

            plt.xlabel('Epoch')
            plt.ylabel('Loss')
            plt.title(f'Loss Curve - {region_name}')
            plt.legend()
            plt.grid(True)
            plt.tight_layout()
            plt.savefig(f'artifacts/loss_curve_{region_name}.png', dpi=150)
            plt.close()

            print(f"ðŸ“‰ Saved loss curve â†’ artifacts/loss_curve_{region_name}.png")

            end_time = time.time()     # <-- End timer
            elapsed = (end_time - start_time) / 60  # minutes
            log_training_time(region_name, elapsed, best_val_loss, cfg.training.epochs, cfg.training.batch_size)
        
            print(f"âœ… Finished training for {region_name} | Best val loss: {best_val_loss:.4f}")
            print(f"â± Training time for {region_name}: {elapsed:.2f} minutes\n")
        
        print("ðŸŽ‰ Training complete.")


if __name__ == "__main__":
    main()

